{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikzo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import bs4\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from scrapy import Selector\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt') #winlocker\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from datetime import datetime, time, date\n",
    "import scrapy\n",
    "from scrapy.selector import Selector\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ДЛЯ КОЛИ!!!!!!!!!!!!!!!!!!!!!\n",
    "import requests\n",
    "#ssylka = 'https://lizaalert.org/forum/viewforum.php?f=184'\n",
    "ssylka = 'https://lizaalert.org/forum/viewforum.php?f=180'\n",
    "html1 = requests.get(ssylka).content #url='google.com'\n",
    "sel1 = Selector(text=html1)\n",
    "course_as11 = sel1.xpath('//a[contains(@class,\"forumtitle\")]')\n",
    "hrefs11_from_css = course_as11.css('::attr(href)')\n",
    "\n",
    "\n",
    "hrefz = list()\n",
    "for i in range(len(hrefs11_from_css.extract())):\n",
    "    clean_link1 = \"https://lizaalert.org/forum\" + str(hrefs11_from_css.extract()[i])[1:]\n",
    "    hrefz.append(clean_link1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALOOOOOOOOOOOO ['3']\n",
      "3\n",
      "[<Selector xpath='//a[contains(@class,\"right-box right\")]' data='<a href=\"./viewforum.php?f=131&amp;sid=d'>]\n",
      "70\n",
      "/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=\n",
      "['/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=', '/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=']\n",
      "[25, 50]\n",
      "[['https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=25', 'https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=50']]\n",
      "['https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=25', 'https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=50']\n",
      "ALOOOOOOOOOOOO ['8']\n",
      "8\n",
      "[<Selector xpath='//a[contains(@class,\"right-box right\")]' data='<a href=\"./viewforum.php?f=162&amp;sid=2'>]\n",
      "70\n",
      "/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=\n",
      "['/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=', '/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=', '/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=', '/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=', '/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=', '/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=', '/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=']\n",
      "[25, 50, 75, 100, 125, 150, 175]\n",
      "[['https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=25', 'https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=50'], ['https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=25', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=50', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=75', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=100', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=125', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=150', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=175']]\n",
      "['https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=25', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=50', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=75', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=100', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=125', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=150', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=175']\n",
      "ALOOOOOOOOOOOO ['2']\n",
      "2\n",
      "[<Selector xpath='//a[contains(@class,\"right-box right\")]' data='<a href=\"./viewforum.php?f=293&amp;sid=1'>]\n",
      "70\n",
      "/viewforum.php?f=293&sid=1ae238930672e5f13a111676227bf85c&start=\n",
      "['/viewforum.php?f=293&sid=1ae238930672e5f13a111676227bf85c&start=']\n",
      "[25]\n",
      "[['https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=25', 'https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=50'], ['https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=25', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=50', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=75', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=100', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=125', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=150', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=175'], ['https://lizaalert.org/forum/viewforum.php?f=293&sid=1ae238930672e5f13a111676227bf85c&start=25']]\n",
      "['https://lizaalert.org/forum/viewforum.php?f=293&sid=1ae238930672e5f13a111676227bf85c&start=25']\n",
      "ALOOOOOOOOOOOO ['4']\n",
      "4\n",
      "[<Selector xpath='//a[contains(@class,\"right-box right\")]' data='<a href=\"./viewforum.php?f=157&amp;sid=6'>]\n",
      "70\n",
      "/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=\n",
      "['/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=', '/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=', '/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=']\n",
      "[25, 50, 75]\n",
      "[['https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=25', 'https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=50'], ['https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=25', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=50', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=75', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=100', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=125', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=150', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=175'], ['https://lizaalert.org/forum/viewforum.php?f=293&sid=1ae238930672e5f13a111676227bf85c&start=25'], ['https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=25', 'https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=50', 'https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=75']]\n",
      "['https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=25', 'https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=50', 'https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=75']\n",
      "[['https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=25', 'https://lizaalert.org/forum/viewforum.php?f=131&sid=da9e3ba53a7e15621027ea10ed77fa54&start=50'], ['https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=25', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=50', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=75', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=100', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=125', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=150', 'https://lizaalert.org/forum/viewforum.php?f=162&sid=25bde2bba66d25ed5f583f858b1e1d7c&start=175'], ['https://lizaalert.org/forum/viewforum.php?f=293&sid=1ae238930672e5f13a111676227bf85c&start=25'], ['https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=25', 'https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=50', 'https://lizaalert.org/forum/viewforum.php?f=157&sid=64e64c0c71e7ffe2ce0613221ff04899&start=75']] ГДЕ Я БЛЯТЬ\n"
     ]
    }
   ],
   "source": [
    "# Import requests\n",
    "import requests\n",
    "\n",
    "list_of_all_pages = list()\n",
    "# Create the string html containing the HTML source\n",
    "for i in range(len(hrefz)):\n",
    "    html = requests.get(hrefz[i]).content #url='google.com'\n",
    "    sel = Selector(text=html)\n",
    "\n",
    "\n",
    "    uClient = uReq(hrefz[i])\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, \"html.parser\")\n",
    "    containers2 = page_soup.findAll(\"div\", {\"class\":\"pagination\"})\n",
    "    containers22 = str(containers2)\n",
    "    #print(containers22)\n",
    "\n",
    "    def page12(containers22):\n",
    "        page1 = list()\n",
    "        c = containers22.find(\"из \")\n",
    "        page1.append(containers22[c+11])\n",
    "        page1.append(containers22[c+12])\n",
    "        if containers22[c+12] == \"<\":\n",
    "            page1.pop()\n",
    "        return page1\n",
    "\n",
    "    print('ALOOOOOOOOOOOO', page12(containers22))\n",
    "    if len(page12(containers22)) == 2:\n",
    "        page_real = int(page12(containers22)[0] + page12(containers22)[1])\n",
    "    else:\n",
    "        page_real = int(page12(containers22)[0])\n",
    "    print(page_real)\n",
    "\n",
    "    # Парсим\n",
    "    course_as = sel.xpath('//a[contains(@class,\"right-box right\")]')\n",
    "    print(course_as)\n",
    "    hrefs_from_css = course_as.css('::attr(href)')\n",
    "    print(len(str(hrefs_from_css.extract())[1:]))\n",
    "    #next1 = \"https://lizaalert.org/forum\" + str(hrefs_from_css.extract()[0])[1:]\n",
    "    #print(\"ссылка=\", next1)\n",
    "    if len(str(hrefs_from_css.extract())[1:]) == 1:\n",
    "        links_to_follow = ssylka\n",
    "        clean_link = ssylka\n",
    "    else:\n",
    "        links_to_follow = \"\\\"https://lizaalert.org/forum\" + str(hrefs_from_css.extract()[0])[1:] + \"\\\"\"\n",
    "        clean_link = str(hrefs_from_css.extract()[0])[1:len(hrefs_from_css.extract()[0])-2]\n",
    "    print(clean_link)\n",
    "    list_links = list()\n",
    "    for i in range((page_real)-1):\n",
    "        list_links.append(clean_link)\n",
    "    print(list_links)\n",
    "\n",
    "    #За 500 надо пояснить! Но это вроде несложно\n",
    "    i=0\n",
    "    list1 = list()\n",
    "    for i in range(0,(page_real-1)*25, 25):\n",
    "        i = i + 25\n",
    "        list1.append(i)\n",
    "    print(list1)\n",
    "\n",
    "    result = [str(item) for item in list1]\n",
    "\n",
    "    #print(type(result[2]))\n",
    "\n",
    "    for i in range(len(list1)):\n",
    "        list_links[i] += result[i]\n",
    "    #print(list_links)\n",
    "\n",
    "    for i in range(len(list_links)):\n",
    "        list_links[i] = \"https://lizaalert.org/forum\" + list_links[i]\n",
    "    list_of_all_pages.append(list_links)\n",
    "    print(list_of_all_pages)\n",
    "    print(list_links)\n",
    "    \n",
    "print(list_of_all_pages, \"ГДЕ Я БЛЯТЬ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_all_pages))\n",
    "listSYKA = list()\n",
    "for i in range(len(list_of_all_pages)):\n",
    "    for j in range(len(list_of_all_pages[i])):\n",
    "        listSYKA.append(list_of_all_pages[i][j])\n",
    "\n",
    "for j in range(len(hrefz)):\n",
    "    listSYKA.append(hrefz[j])\n",
    "listSYKA.append(ssylka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    }
   ],
   "source": [
    "list_full = list()\n",
    "for i in range(len(listSYKA)):\n",
    "    #html = requests.get(list_links[i]).content #url='google.com'\n",
    "    html = requests.get(listSYKA[i]).content #url='google.com'\n",
    "    sel = Selector(text=html)\n",
    "\n",
    "    course_as1 = sel.css('a.topictitle')\n",
    "    hrefs1_from_css = course_as1.css('::attr(href)')\n",
    "\n",
    "    list0 = list()\n",
    "    for i in range(0, len(hrefs1_from_css.extract())):\n",
    "        list0.append(\"https://lizaalert.org/forum\" + str(hrefs1_from_css.extract()[i])[1:])\n",
    "        list_full.append(list0[i])\n",
    "#print(list_full)\n",
    "print(len(list_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = list_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n"
     ]
    }
   ],
   "source": [
    "my_list[0]\n",
    "print(len(list_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Здесь соберем все вспомогательные перменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_searchers = []\n",
    "list_photo = []\n",
    "list_state1 = []\n",
    "list_sex1 = []\n",
    "list_age11 = []\n",
    "list_posts = []\n",
    "list_height = []\n",
    "list_help1 = []\n",
    "list_hair_color = []\n",
    "list_bodytype = []\n",
    "list_eye = []\n",
    "list_of_lists = []  ## Здесь нужно додумать\n",
    "list_place = []\n",
    "list_color_of_clothes = []# Бабкен Вставил\n",
    "list_of_lists = []  ## Здесь нужно додумать\n",
    "list_podrobnost = []\n",
    "list_primeti = []\n",
    "list_search_time =[]\n",
    "list_lost_time = []\n",
    "list_find_time = []\n",
    "list_of_coor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = ['.', ',', ':', ';', \"!\", \"?\", '-', ')', '(']\n",
    "months_num = {\"янв\": 1, \"фев\": 2, \"мар\": 3,\"апр\": 4,\"мая\": 5, \"май\": 5,\"июн\": 6,\"июл\": 7,\"авг\": 8,\"сен\": 9,\"окт\": 10,\"ноя\": 11,\"дек\": 12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Напишем все функции, которые нам понадобятся в сборе признаков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchers(containers228):\n",
    "    if containers228 == 'ebanyi obychenie':\n",
    "        searchers = 0\n",
    "    else:\n",
    "        kerka = containers228.findAll(text=re.compile(r'\\w+'))\n",
    "        kerka1 = containers228.findAll(text=re.compile(r'На месте|НА МЕСТЕ|Дом|ДОМ|Экипаж|ЭКИПАЖ'))\n",
    "        searchers = (len(kerka) - len(kerka1))\n",
    "    return searchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def photo1(containers11):\n",
    "    if containers11.find(\"Изображение\") != -1:\n",
    "        photo =  'присутствует'\n",
    "    else:\n",
    "        photo = 'отсутствует'\n",
    "    return photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state1(title1):\n",
    "    if title1.find(\"Жив\") != -1 or title1.find(\"ЖИВ\") != -1 or title1.find(\"Найден\") != -1 or title1.find(\"НАЙДЕН\") != -1:\n",
    "        state = \"живой\"\n",
    "    elif title1.find(\"Пропал\") != -1 or title1.find(\"ПРОПАЛ\") != -1:\n",
    "        state = 'ищется'\n",
    "    elif title1.find(\"Погиб\") != -1 or title1.find(\"ПОГИБ\") != -1 or title1.find(\"Мертв\") != -1 or title1.find(\"МЕРТВ\") != -1:\n",
    "        state = 'мертвый'\n",
    "    else:\n",
    "        state = \"Не указано\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex1(title1): # Слава вставил 8 мая \n",
    "    sex = re.search(r'[Пп]ропала|[Вв]ышла|[Уу]шла|[Нн]айдена|[Жж]ива|[Ее]ё|[Ее]е|[Ее]го|[Уу]ехала|[Пп]огибла|[Вв]ернулась|не [Вв]ернулась|[Вв]ышел|[Уу]шёл|[Уу]шел|[Пп]ропал|[Нн]айден|[Жж]ив|[Ее]го|[Уу]ехал|[Пп]огиб|[Вв]ернулся|не [Вв]ернулся', title1)\n",
    "    if sex is None:\n",
    "        return \"Er\"\n",
    "    sex = str(sex.group(0))\n",
    "    if sex == \"вышел\" or sex == \"Вышел\" or sex == \"ушел\" or sex == \"Ушел\" or sex == 'ушёл' or sex == 'пропал' or sex == 'Пропал' or sex == 'Найден' or sex == 'найден' or sex == 'ушел'or sex == 'ушёл'or sex == 'пропал'or sex == 'найден'or sex == 'Найден'or sex == 'вышел' or sex == 'Жив'or sex == 'жив' or sex == 'уехал'or sex == 'Погиб'or sex == 'погиб'or sex == 'вернулся':\n",
    "        sex = \"Мужчина\"\n",
    "    else:\n",
    "        sex = \"Женщина\"\n",
    "    return sex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age11(title1):\n",
    "    preage = re.search(r'\\d+', str(title1))\n",
    "    if preage is None:\n",
    "        return \"Коля объебался\"\n",
    "    else:\n",
    "        age = preage.group()\n",
    "        if len(age) == 4:\n",
    "            age = 2019 - int(age)\n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posts1(containers2):\n",
    "    posts = re.search(r'\\d+', str(containers2)).group()\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data1(containers88):\n",
    "    d = containers88.find(\"Инфорг\")\n",
    "    if d == -1:\n",
    "        data1, data2 = 'не','редактировали'\n",
    "    else:\n",
    "        data1 = containers88[d+11] + containers88[d+12] + containers88[d+13] + containers88[d+14] + containers88[d+15] + containers88[d+16] + containers88[d+17] + containers88[d+18] + containers88[d+19] + containers88[d+20] + containers88[d+21]\n",
    "        data2 = containers88[d+24] + containers88[d+25] + containers88[d+26] + containers88[d+27] + containers88[d+28]\n",
    "        data = data1 + ' ' + data2\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def height(containers11): # Вставил Слава 8.05.2019\n",
    "    high = re.search(r'[Рр]ост \\d{3}|[Рр]оста \\d{3}|[Рр]оста\\d{3}|[Рр]ост: \\d{3}|[Рр]ост - \\d{3}|рост\\d{3}-|Рост:\\d{3}| росто \\d{3}', containers11 )\n",
    "    if high is None:\n",
    "        return \"Er\"\n",
    "    high = str(high.group(0))\n",
    "\n",
    "    height = re.findall(r'\\d+',high)\n",
    "    height = int(\" \".join(height))\n",
    "    return height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help1(containers11):\n",
    "    if containers11.find(\"В МЕДИЦИНСКОЙ ПОМОЩИ\") == -1 and containers11.find(\"в медицинской помощи\") == -1:\n",
    "        help1 = 'здоров'\n",
    "    else:\n",
    "        help1 = 'требуется мед. помощь'\n",
    "    return help1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hair_color(contents):\n",
    "    hc = 'Не указано'\n",
    "    for string in contents:\n",
    "        if \"олосы\" in string:\n",
    "            no_stops_string_1 = ''.join([t for t in string if t not in english_stops])\n",
    "            tokens_1 = word_tokenize(no_stops_string_1)\n",
    "            for i in range(len(tokens_1)):\n",
    "                if \"олосы\" in tokens_1[i]:\n",
    "                    hc = tokens_1[i + 1]\n",
    "    return hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Нужно доработать код! Или сделать заново\n",
    "def body_type(contents):\n",
    "    body = \"Не указано\"\n",
    "    for string in contents:\n",
    "        if \"елосложени\" in string:\n",
    "            no_stops_string = ''.join([t for t in string if t not in english_stops])\n",
    "            tokens = word_tokenize(no_stops_string)\n",
    "            tokens.append(\"Ты объебался\")\n",
    "            for i in range(len(tokens)):\n",
    "                if \"елосложени\" in tokens[i]:\n",
    "                    if tokens[i][-1] == \"я\":\n",
    "                        body = tokens[i - 1]\n",
    "                        break\n",
    "                    else:\n",
    "                        body = tokens[i + 1]\n",
    "                        break\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Нужно доработать код! Или сделать заново\n",
    "def eyes_color(contents):\n",
    "    ec = \"Не указано\"\n",
    "    for string in contents:\n",
    "        if \"лаз\" in string:\n",
    "            no_stops_string = ''.join([t for t in string if t not in english_stops])\n",
    "            tokens = word_tokenize(no_stops_string)\n",
    "            tokens.append(\"Кто-то объебался\")\n",
    "            for i in range(len(tokens)):\n",
    "                if \"лаз\" in tokens[i]:\n",
    "                    ec = tokens[i + 1]\n",
    "                if ec == \"Кто-то объебался\":\n",
    "                    ec = tokens[i-1]\n",
    "                    break\n",
    "    return ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yebanskii(sel):\n",
    "    p = sel.css(\"div.content\").xpath('./span[@style=\"font-size: 140%; line-height: 116%;\"]/span[@style=\"font-weight: bold\"]/text()').extract()\n",
    "    a = str(p)\n",
    "    b = re.split('\\s+', a)\n",
    "    b1 = b[5:]\n",
    "    t = str(b1)\n",
    "    p = t.replace(\"\\'\", \"\")\n",
    "    p1 = p.replace(']', '')\n",
    "    p2 = p1.replace('[', '')\n",
    "    p3 = p2.replace('\"', '')\n",
    "    p4 = p3.replace(', ', \" \")\n",
    "    p5 = p4.replace('- ','-')\n",
    "    return p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_cloth(containers11):\n",
    "    containers1 = re.split('<span style=\"font-weight: bold\">', containers11)\n",
    "    if len(containers1) < 4:\n",
    "        return \"Не указано\"\n",
    "    else:\n",
    "        containers_new = containers1[3]\n",
    "        black = len(re.findall(r'черн', containers_new))\n",
    "        white = len(re.findall(r'бел', containers_new))\n",
    "        yellow = len(re.findall(r'желт', containers_new))\n",
    "        orange = len(re.findall(r'оранж', containers_new))\n",
    "        br_grey = len(re.findall(r'тло-сер', containers_new))\n",
    "        grey = len(re.findall(r'сер', containers_new))\n",
    "        beg = len(re.findall(r'бежев', containers_new))\n",
    "        br_blue = len(re.findall(r'тло-син', containers_new))\n",
    "        blue = len(re.findall(r'син', containers_new))\n",
    "        green = len(re.findall(r'зелен', containers_new))\n",
    "        violent = len(re.findall(r'фиол', containers_new))\n",
    "        black1 = len(re.findall(r'чёрн', containers_new))\n",
    "        brown = len(re.findall(r'коричн', containers_new))\n",
    "        al_colors = black + yellow + orange + grey + beg + blue + green + violent + black1\n",
    "        br_colors1 = white + yellow + orange + br_grey + beg + br_blue + green + violent\n",
    "        br_colors2 = white + yellow + orange + beg + br_blue + green + violent\n",
    "        br_colors3 = white + yellow + orange + br_grey + beg + green + violent\n",
    "        br_colors4 = white + yellow + orange + beg + green + violent\n",
    "        dk_colors1 = black + black1 + brown\n",
    "        dk_colors2 = black + grey + black1 + brown\n",
    "        dk_colors3 = black + blue + black1 + brown\n",
    "        dk_colors4 = black + blue + grey + black1 + brown\n",
    "        if al_colors == 0:\n",
    "            return \"Не указано\" \n",
    "        elif (br_grey == 0 and br_blue == 0) and br_colors4 >= dk_colors4:\n",
    "            return \"Яркая\"\n",
    "        elif (br_grey == 0 and br_blue == 0) and br_colors4 < dk_colors4:\n",
    "            return \"Темная\"\n",
    "        elif ((br_grey != 0 and grey != 0) or (br_blue != 0 and blue != 0 )) and br_colors1 >= dk_colors4:\n",
    "            return \"Яркая\"\n",
    "        elif ((br_grey != 0 and grey != 0) or (br_blue != 0 and blue != 0 )) and br_colors1 < dk_colors4:\n",
    "            return \"Темная\"\n",
    "        elif (br_grey == 0) and br_colors2 >= dk_colors2:\n",
    "            return \"Яркая\" \n",
    "        elif (br_grey == 0) and br_colors2 < dk_colors2:\n",
    "            return \"Темная\" \n",
    "        elif (br_blue == 0) and br_colors3 >= dk_colors3:\n",
    "            return \"Яркая\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def podrobnost(containers11):\n",
    "    containers1 = re.split('<span style=\"font-weight: bold\">', containers11)\n",
    "    if len(containers1) < 4:\n",
    "        return(\"Не указано\")\n",
    "    else:\n",
    "        containers_new = containers1[3]\n",
    "        containers_new_sep = containers_new.split(',')\n",
    "        l = len(containers_new_sep)\n",
    "        if l > 3:\n",
    "            return 4\n",
    "        elif 2 <= l < 3:\n",
    "            return 3\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primeti(containers11):\n",
    "    containers1 = re.split('<span style=\"font-weight: bold\">', containers11)\n",
    "    if len(containers1) < 5:\n",
    "        return(\"Не указано\")\n",
    "    else:\n",
    "        containers_new = containers1[4]\n",
    "        containers_new_sep = containers_new.split(',')\n",
    "        l = len(containers_new_sep)\n",
    "        if l > 3:\n",
    "            return 4\n",
    "        elif 2 <= l < 3:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lost_timing(x):\n",
    "    if re.search(r'\\d+ \\w+ \\d{4}|\\d{2}.\\d{2}.\\d{4}', x) == None:\n",
    "        return \"Сбой\"\n",
    "    else:\n",
    "        lost_time = re.search(r'\\d+ \\w+ \\d{4}|\\d{2}.\\d{2}.\\d{4}', x).group()\n",
    "        print(lost_time)\n",
    "        if \"я\" in lost_time or \"т\" in lost_time:\n",
    "            lts = lost_time.split()\n",
    "            print(lts)\n",
    "            lts[1] = months_num[lts[1][:3]]\n",
    "            lts = list(map(int, lts))\n",
    "            lost_time = date(lts[-1], lts[-2], lts[-3])\n",
    "            return lost_time\n",
    "            #lost_time = date(lts[-1], [-2], [-3])\n",
    "        else:\n",
    "            lts = lost_time.split('.')\n",
    "            lts = list(map(int, lts))\n",
    "            lost_time = date(lts[-1], lts[-2], lts[-3])\n",
    "            return lost_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_timing(x):\n",
    "    if re.search(r'\\d+ \\w+ \\d{4}|\\d{2}.\\d{2}.\\d{4}', x) == None:\n",
    "        return \"Сбой\"\n",
    "    else:\n",
    "        find_time = re.search(r'\\d+ \\w+ \\d{4}|\\d{2}.\\d{2}.\\d{4}', x).group()\n",
    "        print(find_time)\n",
    "        fts = find_time.split()\n",
    "        print(fts)\n",
    "        fts[1] = months_num[fts[1]]\n",
    "        fts = list(map(int, fts))\n",
    "        find_time = date(fts[-1], fts[-2], fts[-3])\n",
    "        return find_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_timing(x, y):\n",
    "    return (find_timing(y) - lost_timing(x)).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_format(function, x):\n",
    "    if len(str(function(x).day)) == 1:\n",
    "        day = \"0\" + str(function(x).day)\n",
    "    else:\n",
    "        day = str(function(x).day)\n",
    "    if len(str(function(x).month)) == 1:\n",
    "        month = \"0\" + str(function(x).month)\n",
    "    else:\n",
    "        month = str(function(x).month)\n",
    "    return day + \".\" + month + \".\" + str(function(x).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cor(comp):\n",
    "    for i in range (len(comp)):\n",
    "        contents = page_soup.findAll(\"div\", {\"class\":\"content\"})[i].contents\n",
    "        kavka = re.search(r'\\d+.\\d+, \\d+.\\d+|\\d+.\\d+,\\d+.\\d+|\\d+.\\d+ \\d+.\\d+', str(contents))\n",
    "        if kavka is not None:\n",
    "            kavkaz = kavka.group()\n",
    "            break\n",
    "        else:\n",
    "            kavkaz = 'no cord'\n",
    "    return kavkaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перейдем к сбору признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in my_list:\n",
    "    my_url = i\n",
    "    uClient = uReq(my_url)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, \"html.parser\")\n",
    "    title = page_soup.title\n",
    "    title1 = str(title)\n",
    "\n",
    "    comp = page_soup.findAll(\"div\", {\"class\":\"content\"})\n",
    "    containers = page_soup.findAll(\"div\", {\"class\":\"content\"})\n",
    "    contents = page_soup.findAll(\"div\", {\"class\":\"content\"})[0].contents\n",
    "    containers11 = str(containers)\n",
    "    containers2 = page_soup.findAll(\"div\", {\"class\":\"pagination\"})\n",
    "    containers22 = str(containers2)\n",
    "    containers8 = page_soup.findAll(\"div\", {\"class\":\"notice\"})\n",
    "    containers88 = str(containers8) \n",
    "    containers1 = re.split('<span style=\"font-weight: bold\">', containers11)\n",
    "    #containers1\n",
    "    if len(page_soup.findAll(\"div\", {\"class\":\"content\"})) > 1:\n",
    "        containers228 = page_soup.findAll(\"div\", {\"class\":\"content\"})[1]\n",
    "    else:\n",
    "        containers228 = 'ebanyi obychenie'\n",
    "    \n",
    "    list_searchers.append(searchers(containers228))\n",
    "    list_photo.append(photo1(containers11))\n",
    "    list_state1.append(state1(title1))\n",
    "    list_sex1.append(sex1(title1))\n",
    "    list_age11.append(age11(title1))\n",
    "    list_posts.append(posts1(containers22))\n",
    "    #list_hair_color.append(hair_color(contents))\n",
    "    list_bodytype.append(body_type(contents))\n",
    "    list_eye.append(eyes_color(contents))\n",
    "    containers = page_soup.findAll(\"div\", {\"class\":\"content\"})\n",
    "    containers11 = str(containers)\n",
    "    list_height.append(height(containers11))\n",
    "    list_help1.append(help1(containers11))\n",
    "    list_place.append(yebanskii(sel))\n",
    "    list_color_of_clothes.append(color_cloth(containers11)) # Бабкен вставил\n",
    "    list_podrobnost.append(podrobnost(containers11)) # Бабкен вставил еще раз, но уже Ване\n",
    "    list_primeti.append(primeti(containers11))\n",
    "    if page_soup.find('div', {'class':'content'}) != None and page_soup.find('div', {'class':'notice'}) != None:\n",
    "        main = page_soup.find('div', {'class':'content'}).text\n",
    "        notmain = page_soup.find('div', {'class':'notice'}).text\n",
    "        #if lost_timing(main) != \"Сбой\" and find_timing(notmain) != \"Сбой\":\n",
    "        #    list_search_time.append(search_timing(main, notmain))\n",
    "        #    list_lost_time.append(super_format(lost_timing, main))\n",
    "        #    list_find_time.append(super_format(find_timing,notmain))\n",
    "        #else:\n",
    "        #    list_search_time.append(\"Ошибка\")\n",
    "        #    list_lost_time.append(\"Ошибка\")\n",
    "        #    list_find_time.append(\"Ошибка\")\n",
    "    #else:\n",
    "        #list_search_time.append(\"Ошибка\")\n",
    "        #list_lost_time.append(\"Ошибка\")\n",
    "        #list_find_time.append(\"Ошибка\")\n",
    "    #html = requests.get(my_url).content\n",
    "    #sel = Selector(text= html)\n",
    "    #if sel.xpath('//div[@class=\"content\"]//span[@style=\"text-decoration: line-through;\"]').extract_first() != None:\n",
    "    #    line = sel.xpath('//div[@class=\"content\"]//span[@style=\"text-decoration: line-through;\"]').extract_first()\n",
    "    #else:\n",
    "    #    line = \"no coordinates\"\n",
    "    list_of_coor.append(find_cor(comp))\n",
    "#print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '303-9011, 8-964',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '44.798627, 38.637727',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '45.024527, 38.974713',\n",
       " '46,185300, 39,436079',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '44.731529, 37.741134',\n",
       " 'no cord',\n",
       " '45.456156, 39.445658',\n",
       " 'no cord',\n",
       " '45.227154, 38.999370',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '45.087765, 38.980757',\n",
       " '44,5463990, 38,2235640',\n",
       " '45.299099, 39.932770',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '44.923438, 37.983729',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '45.220209, 39.226760',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '45.032980, 38.997061',\n",
       " 'no cord',\n",
       " '46.039774, 38.193887',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '45.290280, 39.556061',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '44.818409, 37.934841',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '44.748184, 39.006432',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '89-29, 8-985',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '10/17, 12.02',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '45.272083, 33.089038',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '16,17,18,19',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '29.05, 30.05',\n",
       " 'no cord',\n",
       " '45.019481, 38.998771',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '44.175571, 40.619266',\n",
       " 'no cord',\n",
       " '43.585636, 39.725936',\n",
       " '45.056715, 39.010159',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '45.033369, 39.002047',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " '45.151649, 41.121476',\n",
       " 'no cord',\n",
       " '45.006367, 39.016321',\n",
       " '45.036130, 39.011412',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord',\n",
       " 'no cord']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_coor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсим посты, копаем вглубь!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_pages1 = list()\n",
    "\n",
    "for i in my_list:\n",
    "    URL = i\n",
    "    \n",
    "    html = requests.get(URL).content #url='google.com'\n",
    "    sel = Selector(text=html)\n",
    "\n",
    "    uClient = uReq(URL)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, \"html.parser\")\n",
    "    containers2 = page_soup.findAll(\"div\", {\"class\":\"pagination\"})\n",
    "    containers22 = str(containers2)\n",
    "\n",
    "    def page12(containers22):\n",
    "        page1 = list()\n",
    "        c = containers22.find(\"из \")\n",
    "        page1.append(containers22[c+11])\n",
    "        page1.append(containers22[c+12])\n",
    "        if containers22[c+12] == \"<\":\n",
    "            page1.pop()\n",
    "            return page1\n",
    "\n",
    "    if page12(containers22) is None:\n",
    "        page_real = 1\n",
    "    else:\n",
    "        if len(page12(containers22)) == 2:\n",
    "            page_real = int(page12(containers22)[0] + page12(containers22)[1])\n",
    "        else:\n",
    "            page_real = int(page12(containers22)[0])\n",
    "\n",
    "        # Парсим\n",
    "    course_as = sel.xpath('//a[contains(@class,\"right-box right\")]')\n",
    "    hrefs_from_css = course_as.css('::attr(href)')\n",
    "\n",
    "    if len(str(hrefs_from_css.extract())[1:]) == 1:\n",
    "        links_to_follow = URL\n",
    "        clean_link = URL[27:len(URL)]\n",
    "    else:\n",
    "        links_to_follow = \"\\\"https://lizaalert.org/forum\" + str(hrefs_from_css.extract()[0])[1:] + \"\\\"\"\n",
    "        clean_link = str(hrefs_from_css.extract()[0])[1:len(hrefs_from_css.extract()[0])-2]\n",
    "\n",
    "    list_links = list()\n",
    "    for i in range((page_real)):\n",
    "        list_links.append(clean_link)\n",
    "\n",
    "\n",
    "        #За 500 надо пояснить! Но это вроде несложно\n",
    "    i=0\n",
    "    list1 = [0]\n",
    "    for i in range(0,(page_real-1)*10, 10):\n",
    "        i = i + 10\n",
    "        list1.append(i)\n",
    "\n",
    "    result = [str(item) for item in list1]\n",
    "\n",
    "    for i in range(len(list1)):\n",
    "        if list_links[i].find(\"start\") != -1:\n",
    "            list_links[i] += result[i]\n",
    "        \n",
    "    for i in range(len(list_links)):\n",
    "        list_links[i] = \"https://lizaalert.org/forum\" + list_links[i]\n",
    "    \n",
    "    list_of_all_pages1.append(list_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://lizaalert.org/forum/viewtopic.php?f=131&t=9861&sid=b1eac71a80b12b561b721b0a4718b35b']\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[1;32m-> 1317\u001b[1;33m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[0;32m   1318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1274\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1275\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    955\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    957\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    927\u001b[0m         self.sock = self._create_connection(\n\u001b[1;32m--> 928\u001b[1;33m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-86e6f2f92945>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_all_pages1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mvk_post\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0muClient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muReq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_all_pages1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mpage_html\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muClient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0muClient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1360\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1317\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1319\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1320\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера>"
     ]
    }
   ],
   "source": [
    "print(list_of_all_pages1[1])\n",
    "list_vk_posts = []\n",
    "for j in range(len(list_of_all_pages1)):\n",
    "    vk_posts = 0\n",
    "    vk_postes = []\n",
    "    for item in range(len(list_of_all_pages1[j])):\n",
    "        vk_post = []\n",
    "        uClient = uReq(list_of_all_pages1[j][item])\n",
    "        page_html = uClient.read()\n",
    "        uClient.close()\n",
    "        page_soup = soup(page_html, \"html.parser\")\n",
    "        for p in range(len(page_soup.findAll(\"div\", {\"class\":\"content\"}))):\n",
    "            containers2 = page_soup.findAll(\"div\", {\"class\":\"content\"})[p] #ЧТО ЭТО ЗА ХУЙНЯ?????????\n",
    "            kirka = containers2.findAll(text=re.compile(\"vk.com\"))\n",
    "            vk_post.append(len(kirka))\n",
    "        vk_postes.append(vk_post)\n",
    "    vk_posts += vk_posts\n",
    "    for i in range(len(vk_postes)):\n",
    "        for k in range(len(vk_postes[i])):\n",
    "            vk_posts += vk_postes[i][k]\n",
    "    list_vk_posts.append(vk_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_of_all_pages1[1])\n",
    "list_odn_posts = []\n",
    "for j in range(len(list_of_all_pages1)):\n",
    "    odn_posts = 0\n",
    "    odn_postes = []\n",
    "    odn_post = []\n",
    "    for item in range(len(list_of_all_pages1[j])):\n",
    "        uClient = uReq(list_of_all_pages1[j][item])\n",
    "        page_html = uClient.read()\n",
    "        uClient.close()\n",
    "        page_soup = soup(page_html, \"html.parser\")\n",
    "        for p in range(len(page_soup.findAll(\"div\", {\"class\":\"content\"}))):\n",
    "            containers2 = page_soup.findAll(\"div\", {\"class\":\"content\"})[p] #ЧТО ЭТО ЗА ХУЙНЯ?????????\n",
    "            kirka = containers2.findAll(text=re.compile(r'odnokl|ok.ru'))\n",
    "            odn_post.append(len(kirka))\n",
    "    odn_postes.append(odn_post)\n",
    "    odn_posts += odn_posts\n",
    "    for i in range(len(odn_postes)):\n",
    "        for k in range(len(odn_postes[i])):\n",
    "            odn_posts += odn_postes[i][k]\n",
    "    list_odn_posts.append(odn_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_of_all_pages1[0])\n",
    "list_ready_posts = []\n",
    "for j in range(len(list_of_all_pages1)):\n",
    "    ready_posts = 0\n",
    "    ready_postes = []\n",
    "    for item in range(len(list_of_all_pages1[j])):\n",
    "        ready_post = []\n",
    "        uClient = uReq(list_of_all_pages1[j][item])\n",
    "        page_html = uClient.read()\n",
    "        uClient.close()\n",
    "        page_soup = soup(page_html, \"html.parser\")\n",
    "        for p in range(len(page_soup.findAll(\"div\", {\"class\":\"content\"}))):\n",
    "            containers2 = page_soup.findAll(\"div\", {\"class\":\"content\"})[p] #ЧТО ЭТО ЗА ХУЙНЯ?????????\n",
    "            kirka = containers2.findAll(text=re.compile(r'[Гг]отов'))\n",
    "            ready_post.append(len(kirka))\n",
    "        ready_postes.append(ready_post)\n",
    "    ready_posts += ready_posts\n",
    "    for i in range(len(ready_postes)):\n",
    "        for k in range(len(ready_postes[i])):\n",
    "            ready_posts += ready_postes[i][k]\n",
    "    list_ready_posts.append(ready_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists.append(list_ready_posts)\n",
    "list_of_lists.append(list_searchers)\n",
    "list_of_lists.append(list_vk_posts)\n",
    "list_of_lists.append(list_odn_posts)\n",
    "list_of_lists.append(list_age11)\n",
    "list_of_lists.append(list_height)\n",
    "list_of_lists.append(list_help1)\n",
    "list_of_lists.append(list_photo)\n",
    "list_of_lists.append(list_posts)\n",
    "list_of_lists.append(list_sex1)\n",
    "list_of_lists.append(list_state1)\n",
    "list_of_lists.append(list_hair_color)\n",
    "list_of_lists.append(list_bodytype)\n",
    "list_of_lists.append(list_eye)\n",
    "list_of_lists.append(list_full)\n",
    "list_of_lists.append(list_place)\n",
    "list_of_lists.append(list_color_of_clothes) # Бабкен вставил\n",
    "list_of_lists.append(list_podrobnost) # Бабкен вставил еще раз, но уже себе\n",
    "list_of_lists.append(list_primeti)\n",
    "list_of_lists.append(list_search_time)\n",
    "list_of_lists.append(list_lost_time)\n",
    "list_of_lists.append(list_find_time)\n",
    "list_of_lists.append(list_of_coor)\n",
    "# Бабкен вставил снова, только Коле в пердачело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(columns = ['Готовые', 'Искатели', 'Репосты_вк', 'Репосты_одн', 'Возраст', 'Рост(Slava)', 'Мед. Состояние', 'Фото', 'Посты', 'Гендер(Slava)', 'Состояние(Slava)', 'Цвет волос', 'Телосложение', 'Цвет глаз', 'Url','Место', 'Одежда(яркая)', 'Одежда(подробность)', 'Приметы(кол-во)', 'Время поиска', \"Время пропажи\", \"Время нахождения\", \"Координаты пропажи\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(list_of_lists, list(df1.columns)):\n",
    "    df1[j] = pd.Series(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тадаам ! Вот , что мы получили"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df1[\"Время поиска\"][df1[\"Время поиска\"] == \"Ошибка\"])/ len(df1[\"Время поиска\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_coor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока дальше не нужно смотреть ( Славе)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for element in  df1[\"Телосложение\"][:19]:\n",
    "    if element == \"Не указано\":\n",
    "        count += 1\n",
    "count/len(df1[\"Телосложение\"][:19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"post7.csv\"\n",
    "f = open(filename, \"w\")\n",
    "headers = \"age1, height, posts\\n\"\n",
    "f.write(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так, осталось выпарсить (хотя бы ублюдочно):\n",
    "1) время пропажи\n",
    "2) телосложение\n",
    "3) цвет глаз\n",
    "4) волосы\n",
    "5) одежда???\n",
    "\n",
    "А сейчас PPPPANDA, PPPAND, PPPPPPPANDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAAAANDA, PPPPANDA, LADDDNO (c) illumate & obladaet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
